{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caffe to Caffe2 Translator Tutorial\n",
    "In this example we will convert a pre-existing Caffe model into a format that will be supported by Caffe2. This tutorial requires the following additional modules that you may not have installed yet:\n",
    "\n",
    "- matpotlib\n",
    "- skimage\n",
    "\n",
    "Use conda, pip, or `sudo apt-get install` to get these modules.\n",
    "\n",
    "You will also need the original Caffe repo because this tutorial uses tools and resources from Caffe. You configure the Caffe location in the second code block below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from caffe.proto import caffe_pb2\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from cStringIO import StringIO\n",
    "from google.protobuf import text_format\n",
    "from IPython import display\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "from caffe2.python import caffe_translator, visualize, workspace, net_drawer\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will set your file path in `CAFFE_ROOT` according to your current installation of Caffe.\n",
    "You will also set the model that you're converting with `MODEL`. This will be matched with the filename of the model that you may already have downloaded, or else the script will go fetch the pre-trained model (ilsvrc_aux) for you from the BVLC repository using the script included. Note that the required resources here are:\n",
    "\n",
    "* Pretrained binary: .caffemodel\n",
    "* Model file: deploy.prototxt\n",
    "\n",
    "A sample file of a cat is prepped to be tested after the Caffe model has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houston, you may have a problem. Did you change CAFFE_ROOT to point to your local Caffe repo? Try running: git clone https://github.com/BVLC/caffe.git\n",
      "Loading models...\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jiayq/Research/caffe/models/bvlc_googlenet/deploy.prototxt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ef0d001bf01c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcaffenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcaffenet_pretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAFFE_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffenet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mcaffenet_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAFFE_PRETRAINED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/jiayq/Research/caffe/models/bvlc_googlenet/deploy.prototxt'"
     ]
    }
   ],
   "source": [
    "# This should point to the root folder of Caffe that you checked\n",
    "# out from https://github.com/BVLC/caffe\n",
    "# You can do it by\n",
    "#     git clone https://github.com/BVLC/caffe.git\n",
    "CAFFE_ROOT = '~/caffe'\n",
    "if not os.path.exists(CAFFE_ROOT):\n",
    "    print(\"Houston, you may have a problem. Did you change CAFFE_ROOT to point to your local Caffe repo? Try running: git clone https://github.com/BVLC/caffe.git\")\n",
    "\n",
    "#MODEL = 'bvlc_reference_caffenet'\n",
    "MODEL = 'bvlc_googlenet'\n",
    "\n",
    "CAFFE_MODEL_FILE = os.path.join(\n",
    "    CAFFE_ROOT, 'models', MODEL, 'deploy.prototxt')\n",
    "CAFFE_PRETRAINED = os.path.join(\n",
    "    CAFFE_ROOT, 'models', MODEL, MODEL + '.caffemodel')\n",
    "if not os.path.exists(CAFFE_MODEL_FILE):\n",
    "    os.system(\n",
    "        os.path.join(CAFFE_ROOT, 'scripts/download_model_binary.py') +\n",
    "        ' ' +\n",
    "        os.path.join(CAFFE_ROOT, 'models', MODEL))\n",
    "    os.system(os.path.join(CAFFE_ROOT, 'data/ilsvrc12/get_ilsvrc_aux.sh'))\n",
    "\n",
    "IMAGE_FILE = 'images/cat.jpg'\n",
    "print('Loading models...')\n",
    "caffenet = caffe_pb2.NetParameter()\n",
    "caffenet_pretrained = caffe_pb2.NetParameter()\n",
    "text_format.Merge(open(CAFFE_MODEL_FILE).read(), caffenet)\n",
    "caffenet_pretrained.ParseFromString(open(CAFFE_PRETRAINED).read())\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step the model will be translated to Caffe2 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform translation, using the caffenet and pretrained parameters.\n",
    "print 'Translating model.'\n",
    "net, pretrained_params = caffe_translator.TranslateModel(\n",
    "    caffenet, caffenet_pretrained, is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun we can print out a graph of the operators. We can also change the code below to have it graph the blobs too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = net_drawer.GetPydotGraphMinimal(net.op, net.name, rankdir=\"LR\")\n",
    "print net.name\n",
    "display.Image(graph.create_png(), width=800)\n",
    "# The above command shows only the operators. If you want to see both the\n",
    "# operators and the blobs, use the command below.\n",
    "#graph = net_drawer.GetPydotGraph(net.operators, net.name, rankdir=\"BT\")\n",
    "#display.Image(graph.create_png(), width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list them by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tensor in pretrained_params.protos:\n",
    "    print tensor.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next step of actually running the network, you have the option of CPU or GPU. It is setup for CPU by default, so if you want to use GPU you need to switch the comments below to enable the appropriate lines.\n",
    "\n",
    "`pycaffe2.workspace` implements a very simple Model object that wraps the construction of the model. Specifically, what it will do is:\n",
    "(1) feed the parameters to the workspace;\n",
    "(2) Create input blob placeholders;\n",
    "(3) Actually instantiating the Caffe network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will first specify the device option: how we want to run the network.\n",
    "net.device_option.device_type = caffe2_pb2.CPU\n",
    "# If you want to use cuda, use the following commands\n",
    "#net.device_option.device_type = caffe2_pb2.CUDA\n",
    "#net.device_option.cuda_gpu_id = 0\n",
    "\n",
    "# Here we will simply use the Model object to host the model.\n",
    "model = workspace.Model(net, pretrained_params, [\"data\"], [\"prob\"])\n",
    "print 'Network created sucessfully.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're going to use the test kitty and show processing. It follows these steps:\n",
    "\n",
    "1. Resize the image to 256\\*256, and crop out the center.\n",
    "\n",
    "2. Since Caffe expects CHW order and the current image is HWC, we will need to change the order.\n",
    "\n",
    "3. Caffe uses a BGR order due to legacy OpenCV issues, so we will change RGB to BGR.\n",
    "\n",
    "4. We will subtract the mean image. Note that skimage loads image in the [0, 1] range so we multiply the pixel values first to get them into [0, 255].\n",
    "\n",
    "5. Finally, since caffe2 expects the input to have a batch term so we can feed in multiple images, we will simply prepend a batch dimension of size 1. Also, we will make sure image is of type np.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_FILE = 'images/cat.jpg'\n",
    "# TODO: second declaration of the cat, remove the first?\n",
    "img = skimage.img_as_float(skimage.io.imread(IMAGE_FILE)).astype(np.float32)\n",
    "pyplot.imshow(img)\n",
    "pyplot.axis('off')\n",
    "pyplot.title('Original image')\n",
    "# Here are the steps we use to preprocess the image.\n",
    "# (1) Resize the image to 256*256, and crop out the center.\n",
    "input_height, input_width = 224, 224\n",
    "print 'Input shape is %dx%d' % (input_height, input_width)\n",
    "img = skimage.transform.resize(img, (256, 256))\n",
    "crop_height = (256 - input_height) / 2\n",
    "crop_width = (256 - input_width) / 2\n",
    "img = img[crop_height:crop_height + input_height, \n",
    "          crop_width:crop_width + input_width]\n",
    "pyplot.figure()\n",
    "pyplot.imshow(img)\n",
    "pyplot.axis('off')\n",
    "pyplot.title('Resized image')\n",
    "# (2) Since Caffe expects CHW order and the current image is HWC,\n",
    "#     we will need to change the order.\n",
    "img = img.swapaxes(1, 2).swapaxes(0, 1)\n",
    "# (3) Caffe uses a BGR order due to legacy OpenCV issues, so we\n",
    "#     will change RGB to BGR.\n",
    "img = img[(2, 1, 0), :, :]\n",
    "# (4) We will subtract the mean image. Note that skimage loads\n",
    "#     image in the [0, 1] range so we multiply the pixel values\n",
    "#     first to get them into [0, 255].\n",
    "mean_file = os.path.join(CAFFE_ROOT, 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mean = np.load(mean_file).mean(1).mean(1)\n",
    "img = img * 255 - mean[:, np.newaxis, np.newaxis]\n",
    "pyplot.figure()\n",
    "for i in range(3):\n",
    "    # For some reason, pyplot subplot follows Matlab's indexing\n",
    "    # convention (starting with 1). Well, we'll just follow it...\n",
    "    pyplot.subplot(1, 3, i+1)\n",
    "    pyplot.imshow(img[i])\n",
    "    pyplot.axis('off')\n",
    "    pyplot.title('Input channel %d' % (i+1))\n",
    "# (5) finally, since caffe2 expect the input to have a batch term\n",
    "#     so we can feed in multiple images, we will simply prepend a\n",
    "#     batch dimension of size 1. Also, we will make sure image is\n",
    "#     of type np.float32.\n",
    "img = img[np.newaxis, :, :, :].astype(np.float32)\n",
    "print 'Final input shape is:', img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the aspect ratio in the resized image. Squishy kitty can still be found. It doesn't matter in this example, and as you will see below we get a very high probablity on the prediction. When you convert your own models you will want to prep your test material to fit your expectations and in a manner that you used to create the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = model.Run([img])\n",
    "prob = workspace.FetchBlob('prob').flatten()\n",
    "pyplot.plot(prob)\n",
    "pyplot.title('Prediction')\n",
    "pyplot.axis('off')\n",
    "print 'Max prediction is:', prob.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
